***Feedback and decisions***
We got an overwhelming response to use a webapp instead of pygames, so we will be following that advice. We also decided to try to weight the questions based on the importance to the user, given the feedback to do so. We could either implement it as a slider or a numeric box for ranking importance level. For each question we could have a slider for how important of an issue it is to the user that then weights how much it impacts the users end overall ‘score’

We realized that we need to think more about how we will represent the questions and possible answers; we could either do a summary of bills and yes no answer, or more general ideological questions. 

We also realized that we need to find a good API but are not yet sure of what that would be. Most of the feedback seemed to indicate that as our greatest risk or barrier. As such we decided to make that high priority so we can address any issues that come up in the process. 

***Review process reflection***
The review went well, furthering our understanding of what features our users might think are important to the program that had not thought of before.  All of our questions were answered, some more in depth than others.  We may have provided too much context when going over what our system architecture might look like, but did not take away too much from our overall presentation.  We stuck with the overall agenda, but did not create an overly structured plan because we were unsure of our allotted time going in.  Our topics shifted more towards new features that would bolster the usefulness of our program.  To have a more effective technical review next time, we could have a better presentation platform, including slides with information and pictures.  

